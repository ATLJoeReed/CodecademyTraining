{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit 4 - SciPy - Days 9 & 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project FetchMaker\n",
    "\n",
    "Congratulations! You’ve just started working at the hottest new tech startup, FetchMaker. FetchMaker’s mission is to match up prospective dog owners with their perfect pet. Data on thousands of adoptable dogs are in FetchMaker’s system, and it’s your job to analyze some of that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the data\n",
    "\n",
    "---\n",
    "Let's start by including a data interface called fetchmaker that will give you access to FetchMaker's dog data.\n",
    "\n",
    "Use import fetchmaker at the top of your script.py file to import the fetchmaker package.\n",
    "\n",
    "---\n",
    "The attributes that FetchMaker keeps track of are:\n",
    "\n",
    "weight, an integer representing how heavy a dog is in pounds\n",
    "tail_length, a float representing tail length in inches\n",
    "age, in years\n",
    "color, a String such as \"brown\" or \"grey\"\n",
    "is_rescue, a boolean 0 or 1\n",
    "The fetchmaker package lets you access this data for a specific breed of dog with the following format:\n",
    "\n",
    "fetchmaker.get_weight(\"poodle\")\n",
    "This returns a Pandas DataFrame of the weights of the poodles recorded in the system. The other methods are get_tail_length, get_color, get_age, and get_is_rescue, which all take a breed as an input.\n",
    "\n",
    "Get the tail lengths of all of the \"rottweiler\"s in the system, and store it in a variable called rottweiler_tl.\n",
    "\n",
    "---\n",
    "Print out the mean of rottweiler_tl and the standard deviation of rottweiler_tl, using np.mean and np.std.\n",
    "\n",
    "Data to the rescue\n",
    "\n",
    "---\n",
    "Over the years, we have seen that we expect 8% of dogs in the FetchMaker system to be rescues. We want to know if whippets are significantly more or less likely to be a rescue.\n",
    "\n",
    "Store the is_rescue values for \"whippet\"s in a variable called whippet_rescue.\n",
    "\n",
    "---\n",
    "Use np.count_nonzero to get the number of entries in whippet_rescue that are 1. Store this number in a variable called num_whippet_rescues.\n",
    "\n",
    "---\n",
    "Get the number of samples in the whippet set by taking the np.size of whippet_rescue. Store this in a variable called num_whippets.\n",
    "\n",
    "---\n",
    "Use a binomial test to test the number of whippet rescues, num_whippet_rescues, against our expected percentage, 8%.\n",
    "\n",
    "Remember to import the binomial test by using from scipy.stats import binom_test.\n",
    "\n",
    "---\n",
    "Print out the p-value. Is your result significant?\n",
    "\n",
    "Size does matter\n",
    "\n",
    "---\n",
    "Three of our most popular mid-sized dog breeds are whippets, terriers, and pitbulls. Is there a significant difference in the average weights of these three dog breeds? Perform a comparative numerical test to determine if there is a significant difference.\n",
    "\n",
    "---\n",
    "Now, perform another test to determine which of the pairs of these dog breeds differ from each other.\n",
    "\n",
    "Categorical dog test\n",
    "\n",
    "---\n",
    "We want to see if \"poodle\"s and \"shihtzu\"s have significantly different color breakdowns.\n",
    "\n",
    "Get the poodle colors and store it in a variable called poodle_colors.\n",
    "\n",
    "Get the shih tzu colors and store it in a variable called shihtzu_colors.\n",
    "\n",
    "---\n",
    "You can get the number of occurrences of brown poodles by using np.count_nonzero(poodle_colors == \"brown\").\n",
    "\n",
    "Use this function to build a Chi Square contingency table, called color_table, with the following structure:\n",
    "\n",
    "Poodle\tShih Tzu\n",
    "Black\tx\tx\n",
    "Brown\tx\tx\n",
    "Gold\tx\tx\n",
    "Grey\tx\tx\n",
    "White\tx\tx\n",
    "Fill in the \"x\" entries with the number of each poodle or shih tzu with the specified color.\n",
    "\n",
    "---\n",
    "Feed your color_table into SciPy's Chi Square test, save the p-value and print it out.\n",
    "\n",
    "Is there a significant difference?\n",
    "\n",
    "Good learner! Have a treat!\n",
    "\n",
    "Great job!\n",
    "\n",
    "Feel free to play around with fetchmaker more and run some hypothesis tests of your own.\n",
    "\n",
    "The breeds you can explore are \"poodle\", \"rottweiler\", \"whippet\", \"greyhound\", \"terrier\", \"chihuahua\", \"shihtzu\", and \"pitbull\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2361\n",
      "2.06475368749\n",
      "6\n",
      "100\n",
      "0.581178010624\n",
      "F_onewayResult(statistic=43.249335638174351, pvalue=3.2764155882748152e-17)\n",
      "      Multiple Comparison of Means - Tukey HSD,FWER=0.05      \n",
      "==============================================================\n",
      "     group1          group2     meandiff  lower  upper  reject\n",
      "--------------------------------------------------------------\n",
      "pitbulls_weight terriers_weight  -13.24  -16.728 -9.752  True \n",
      "pitbulls_weight whippets_weight  -3.34    -6.828 0.148  False \n",
      "terriers_weight whippets_weight   9.9     6.412  13.388  True \n",
      "--------------------------------------------------------------\n",
      "black 17\n",
      "brown 13\n",
      "gold 8\n",
      "grey 52\n",
      "white 10\n",
      "--------\n",
      "black 10\n",
      "brown 36\n",
      "gold 6\n",
      "grey 41\n",
      "white 7\n",
      "--------\n",
      "0.00530240829324\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom_test\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "import fetchmaker\n",
    "\n",
    "\n",
    "rottweiler_tl = fetchmaker.get_tail_length(\"rottweiler\")\n",
    "print(np.mean(rottweiler_tl))\n",
    "print(np.std(rottweiler_tl))\n",
    "\n",
    "whippet_rescue = fetchmaker.get_is_rescue(\"whippet\")\n",
    "\n",
    "whippet_rescues = np.count_nonzero(whippet_rescue)\n",
    "print(whippet_rescues)\n",
    "\n",
    "num_whippet_rescue = np.size(whippet_rescue)\n",
    "print(num_whippet_rescue)\n",
    "\n",
    "pval = binom_test(6, n=num_whippet_rescue, p=0.08)\n",
    "print(pval)\n",
    "\n",
    "whippets_weight = fetchmaker.get_weight(\"whippet\")\n",
    "terriers_weight = fetchmaker.get_weight(\"terrier\")\n",
    "pitbulls_weight = fetchmaker.get_weight(\"pitbull\")\n",
    "\n",
    "results = f_oneway(whippets_weight, terriers_weight, pitbulls_weight)\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Using our data from ANOVA, we create v and l\n",
    "v = np.concatenate([whippets_weight, terriers_weight, pitbulls_weight])\n",
    "labels = ['whippets_weight'] * len(whippets_weight) + ['terriers_weight'] * len(terriers_weight) + ['pitbulls_weight'] * len(pitbulls_weight)\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(v, labels, 0.05)\n",
    "print(tukey_results)\n",
    "\n",
    "poodle_colors = fetchmaker.get_color(\"poodle\")\n",
    "shihtzu_colors = fetchmaker.get_color(\"shihtzu\")\n",
    "\n",
    "for color in ['black', 'brown', 'gold', 'grey', 'white']:\n",
    "\tprint(color, np.count_nonzero(poodle_colors == color))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "for color in ['black', 'brown', 'gold', 'grey', 'white']:\n",
    "\tprint(color, np.count_nonzero(shihtzu_colors == color))\n",
    "\n",
    "color_table = [[17,10], [13,36], [8,6], [52,41], [10,7]]\n",
    "\n",
    "print('--------')\n",
    "\n",
    "_, pval, _, _  = chi2_contingency(color_table)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Sample Size and A/B Testing\n",
    "\n",
    "One of the first steps to designing a successful experiment is determining the number of samples that you need in order to have confidence in the results. We don’t want to go to the trouble of running an A/B test or administering a survey only to discover that we don’t have enough information to make a good decision.\n",
    "\n",
    "For instance: if we asked 5 people who they were voting for in an election that small sample would not be sufficient to predict the election results.\n",
    "\n",
    "In this lesson we’ll cover two common types of experiment and their methods of sample size determination:\n",
    "\n",
    "* A/B Tests\n",
    "* Surveys\n",
    "\n",
    "Online sample size calculators are available for both of these scenarios. These calculators will require quantities like “baseline conversion rate” or “population size”, but it’s not always obvious what these should be for a specific experiment. We’ll be covering that and more in this lesson.\n",
    "\n",
    "https://s3.amazonaws.com/codecademy-content/courses/learn-hypothesis-testing/a_b_sample_size/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A/B Testing: Understanding the Baseline\n",
    "\n",
    "A/B tests compare an option that we’re currently using to a new option that we suspect might be better. In order to compare the two options, we need a metric. Generally, our metric will be the percent of users who take a certain action after interacting with one of our options. For instance:\n",
    "\n",
    "* The percent of customers who __buy a t-shirt__ after visiting one of two versions of a website\n",
    "* The percent of users who __click__ on one of two versions of an ad\n",
    "* The percent of readers who __open an email__ with one of two subject lines\n",
    "\n",
    "In order to calculate the sample size for our A/B test, we need to know whether we expect our metric to be low or high. It will take more samples to be able to spot a difference when our metric is extremely low or extremely high. Our initial estimate of our metric is called a baseline.\n",
    "\n",
    "We can usually calculate a baseline by looking at historical data for the option that we’re currently using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A/B Testing: Determining Lift\n",
    "\n",
    "We’re running an A/B Test in order to know if Option B is better than Option A but if Option B were only a tiny percent better, would we really care? In order to detect precise differences, we need a very large sample size. In order to choose a sample size, we need to know the smallest difference that we actually care to measure. This “smallest difference” is called lift.\n",
    "\n",
    "Lift is generally expressed as a percent of the baseline conversion rate. Suppose that 6% of our customers currently buy socks on our website Sock Hops (that’s our baseline conversion rate). We think that a new website layout would increase this. Changing a website layout is hard, so we only think that it’s worth doing if at least 8% of our customers would buy socks on Sock Hops with the new layout. That means that we want to increase our conversions by 2%. \n",
    "\n",
    "To calculate lift:\n",
    "\n",
    "* 100 * (new - old) / old\n",
    "* 100 * (8 - 6) / 6\n",
    "* 33%\n",
    "\n",
    "Sock Hops' desired lift is 33%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "15.0\n"
     ]
    }
   ],
   "source": [
    "# 100 * (Final - Initial) / Initial\n",
    "lift_eight_percent_to_twelve_percent = 100 * (12 - 8) / 8\n",
    "print(lift_eight_percent_to_twelve_percent)\n",
    "\n",
    "# Initial + Initial * Percent Increase\n",
    "ten_percent_up_fifty_percent = (10) + (10 * 0.50)\n",
    "print(ten_percent_up_fifty_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A/B Testing: Don't Interfere With Your Tests\n",
    "\n",
    "Brian the Product Manager has been running an A/B Test for a redesign of Viral Villanelle’s landing page. Brian used the principles in the Sample Size Determination course on Codecademy to calculate a sample size. He needs 1,100 users to view each variant of the landing page in order to be able to detect his desired lift. When he reaches a total of 2,200 visits to both variants, he runs a Chi-Square test. The new website design performs slightly better, but the results are not statistically significant. Brian decides to run the test for another week to see if he can get to significance. He really wants to launch the redesigned website and he needs statistical validation to show to his boss.\n",
    "\n",
    "Brian has made a big mistake! By choosing to extend the A/B test past the sample size he needs, he introduces personal bias to the results of the test.\n",
    "\n",
    "If the results had already been significant, he wouldn’t have run the test any longer. If he continues this pattern of preferentially extending the test when he wants a different answer, he will be more likely to get the results he wants, regardless if these desired results reflect reality.\n",
    "\n",
    "It’s sad, but Brian will need to accept that the redesigned website isn’t significantly better than the original website.\n",
    "\n",
    "Here are two important rules for making sure that A/B tests remain unbiased:\n",
    "\n",
    "* Don’t continue to run the test after the predetermined sample size, until \"significant\" results are found\n",
    "* Don’t stop a test in before reaching the predetermined sample size, just because your results reach significance early (unless there are ethical reasons that require you to stop, like a prescription drug trial)\n",
    "\n",
    "Test data is sensitive to changes in sample size, which is why it is important to calculate beforehand.\n",
    "\n",
    "Instructions\n",
    "Inspect the graph in the workspace. It shows an A/B Test where the baseline was 5%, and we want to see a lift of 50% (i.e., we want our second option to have at least a 7.5% conversion rate). A sample size calculator tells us that we need 210 samples. The chart shows the cumulative conversion rate after each new sample. When we reach our desired 210 samples, our cumulative conversion rate is slightly higher than 5%, but the difference is not significantly different (indicated by red). By extending the experiment to 320 samples, the difference becomes significantly different (indicated by green). We might conclude that our results are significant if we stopped the experiment at this point. However, we can see this is a temporary fluctuation. After this brief moment of \"significance\" the conversion rate decreases and our results become insignificant again. By arbitrarily extending the study until it reaches significance, we fool ourselves!\n",
    "\n",
    "Try this: Flip a coin five times. Which side came up more frequently? Perhaps you now suspect that the coin is biased. Keep flipping the coin until that side shows up even more frequently. By changing your sample size in the middle of an experiment, you can easily convince yourself that a fair coin is biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A/B Testing: Splitting a Test\n",
    "\n",
    "Viral Villanelle's social media presence drives visits to its website. Product Manager Brian wants to test a new ad. Using a sample size calculator, he finds that he will need a sample size of 1,100. Viral Villanelle’s current advertisement is shown to 500 users per day. What’s the best way for Brian to get his desired sample size?\n",
    "\n",
    "It’s important to remember that Brian will need to show both the old and the new ad to 1,100 users each. If Brian wants to get complete this test as quickly as possible, he could randomly divide users into two groups: half of users would see the old ad and half would see the new ad. It would take a little more than 4 days for 2,200 users to see one of the two ads.\n",
    "\n",
    "What if Brian doesn't want to divide Viral Villanelle's audience evenly? If Brian is running many different types of A/B tests, he might not want to expose users to a barrage of different tests. Maybe only 10% of users should be shown the new ad, in case it performs terribly. By doing this, he would only be getting 50 users per day towards the 1,100 users that need to see the new ad. In this case, he would need to wait for 22 days (1100 / 50 = 22) in order to get his results, even though he would have gotten the 1,100 views for the old ad 3 days into the experiment.\n",
    "\n",
    "For his final analysis, Brian should use all of the data from the 22 days. The Chi-Square test Chi Square test will correctly take into account that there is more data from the original ad than from the new ad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Size Calculator for Margin of Error\n",
    "\n",
    "Let's imagine that we own a juice bar called BeetsMe in the small town of Vancucumber. We want to know what our customers' favorite vegetable is so that we know what to base our next juice recipe around. How many people do we need to survey to be confident in our results?\n",
    "\n",
    "It is easy to find a sample size calculator online, but it is harder to determine what parameters to input. Generally, sample size calculators use 4 parameters:\n",
    "\n",
    "* margin of error\n",
    "* confidence level\n",
    "* population size\n",
    "* expected proportion \n",
    "\n",
    "We have provided an example of a sample size calculator for you in the browser to the right. In the next 4 exercises, we will explain what these parameters mean and how we can choose them to accurately represent our experiment\n",
    "\n",
    "https://s3.amazonaws.com/codecademy-content/courses/learn-hypothesis-testing/margin_of_error/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Margin of Error\n",
    "\n",
    "What does it mean to have “enough” people for a survey? Generally, we are making sure that our results are within a margin of error of the correct answer.\n",
    "\n",
    "The margin of error is the furthest we expect the true value to be from what we measure in our survey. For example, let’s say we choose a margin of error of 4%. If we get results showing 40% of people love beets the most, we can be confident that the true proportion in the population lies somewhere between 36% and 44%. Thus, the smaller we make the margin of error, the more certainty we have in the results. The larger we make the margin of error, more uncertain we are that they represent the views of the total population.\n",
    "\n",
    "In order to make our margin of error smaller, we will need a larger sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population Size\n",
    "\n",
    "Our sample should accurately represent the population as a whole. So, when we are dealing with a larger population, we should probably be sampling more people.\n",
    "\n",
    "It is sometimes tricky to determine what the effective population size is. For example, suppose there are 200 people who currently visit BeetsMe regularly. Is 200 the population size for our vegetable survey?\n",
    "\n",
    "If BeetsMe wants to appeal to the tourists that frequently visit Vancucumber, or if they ever want to launch an online store to ship healthy treats all over the world, the real population size is closer to 8 billion (or infinity, really, if we think about the number of humans who could eventually exist and have vegetable preferences). So, for experiments like this, we use the highest population size we can. Normally, 100,000 will suffice, as changes become negligible beyond that.\n",
    "\n",
    "Often, for decisions that require extrapolation to an unknown customer base, it is important to understand the preferences of a typical person out in the world, whether or not they are part of your customer base right now. Generally, we use this larger population size of 100,000 or greater instead of focusing on the amount of current customers.\n",
    "\n",
    "However, if the small town of Vancucumber is holding an election for a new mayor, and we want to project the results of the election, then the 1700 citizens would be the only important people. In this case, 1700 is the population size we would use in a sample size calculator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likely Sample Proportion\n",
    "\n",
    "Often, before we conduct a survey, we have a guess of what we expect the results to be. This guess could be based upon the results from a previous survey, or perhaps the results of a small pilot study before the real study.\n",
    "\n",
    "As the expected proportion of people with the desired trait decreases, we can survey fewer people. For example, if we are projecting election results and Candidate C has 1% of the voter base, taking a small sample of only 5 people might be fine, because it is very likely that no one we have chosen is voting for Candidate C. This is close enough to the true proportion.\n",
    "\n",
    "As the expected proportion increases, it is rarer that we hit that proportion accurately with the random sample we choose.\n",
    "\n",
    "If we do not have historical data, we normally use 50%, which gives the most conservative (i.e., largest required) sample size.\n",
    "\n",
    "https://s3.amazonaws.com/codecademy-content/courses/learn-hypothesis-testing/binomial/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Level\n",
    "\n",
    "We also need to choose a confidence level. The confidence level is the probability that the margin of error contains the true proportion. For example, if we choose a confidence level of 99%, we can expect that after multiple repetitions of the survey, the true value will lie within our specified range 99% of the time. As we increase the confidence level, we necessarily must have a larger sample size.\n",
    "\n",
    "We normally use a confidence level of 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Size of a Survey\n",
    "\n",
    "Once we determine appropriate values the margin of error, confidence level, population size, and expected proportion values for our experiment, we can use a sample size calculator to determine the minimum sample size we need to survey to get the desired confidence in our answer.\n",
    "\n",
    "Let's put together what we've learned so far and determine the appropriate sample size for BeetsMe's vegetable survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differing Survey Results\n",
    "\n",
    "Suppose we are going to survey a group of high school students to see what programming language they want to learn. In the survey, we give the students two choices JavaScript or Python. This seems like a problem where we would use a Sample Size Survey Calculator.\n",
    "\n",
    "But what if we don’t care about getting a specific margin of error? What if instead, we want to make a comparison: Are girls more likely to want to learn Python than boys are?\n",
    "\n",
    "This survey is more similar to an A/B Test. Our baseline is the approximate percent of the population who want to learn Python, and our lift is the minimum difference between boys and girls that we want to be able to detect.\n",
    "\n",
    "Whenever we want to make comparisons between subpopulations in our survey, we must use the A/B Test Calculator in order to get our desired survey size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
